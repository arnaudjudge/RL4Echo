work_dir: ${hydra:runtime.cwd}
run_name: test

logger_run_name: '${get_class_name: ${model._target_}}_${run_name}'

defaults:
  - logger: comet
  - model: rewardnet_3d
  - datamodule: landmark_rewardnet_diff_3d
  - callbacks: default

  - _self_

seed: 1

model:
  save_model_path: ./reward_net_3d_landmarkbigelipse_mse.ckpt

callbacks:
  model_checkpoint:
    monitor: val_loss
    mode: min

run_predict: False

train: True

trainer:
  _target_: lightning.pytorch.Trainer
  max_epochs: 100
  log_every_n_steps: 1
  accelerator: gpu
  accumulate_grad_batches: 16
  devices: 1
  #num_sanity_val_steps: 0 # skip sanity check (convenient for debugging directly in train step)
