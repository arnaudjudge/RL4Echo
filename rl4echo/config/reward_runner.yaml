work_dir: ${hydra:runtime.cwd}
run_name: test

logger_run_name: '${get_class_name: ${model._target_}}_${run_name}'

defaults:
  - logger: comet
  - model: rewardnet
  - datamodule: rewardnet_diff
  - callbacks: default

  - _self_

seed: 1

callbacks:
  model_checkpoint:
    monitor: val_loss
    mode: min

run_predict: False

train: True

trainer:
  _target_: lightning.pytorch.Trainer
  max_epochs: 100
  log_every_n_steps: 1
  accelerator: gpu
  devices: 1
  #num_sanity_val_steps: 0 # skip sanity check (convenient for debugging directly in train step)
