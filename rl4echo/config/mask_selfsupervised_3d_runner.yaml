work_dir: ${hydra:runtime.cwd}
run_name: supervised_default

logger_run_name: '${get_class_name: ${model._target_}}_${run_name}'

defaults:
  - logger: comet
  - model: mask_selfsupervised_3d
  - datamodule: icardio_3d
  - callbacks: default
  - _self_
#  - experiment: supervised_camus

seed: 2

callbacks:
  model_checkpoint:
    monitor: 'val/loss'
    mode: min

predict_subset_frac: 0

datamodule:
  supervised: True
  max_tensor_volume: 5000000 # alright for 24gb gpu (NOT IN RL USE CASE)\
  max_window_len: 4

train: False

model:
  ckpt_path: masked_ssl_seed2.ckpt
test_from_ckpt: /home/local/USHERBROOKE/juda2901/dev/RL4Echo/test_logs/RL4Echo/08d5bee3740d44c4b53df6959988e990/checkpoints/epoch=90-step=5733.ckpt
#/home/local/USHERBROOKE/juda2901/dev/RL4Echo/test_logs/RL4Echo/7ca833f6de2a4a7aa5dd82fddf288e5c/checkpoints/last.ckpt

trainer:
  _target_: lightning.pytorch.Trainer
  max_epochs: 100
  log_every_n_steps: 1
  accelerator: gpu
  devices: 1
  accumulate_grad_batches: 16
  limit_train_batches: 1000
  #num_sanity_val_steps: 0 # skip sanity check (convenient for debugging directly in train step)
